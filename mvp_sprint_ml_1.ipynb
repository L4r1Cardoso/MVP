{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIFRPjn/Pp1Nf5NRx/uGdw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/L4r1Cardoso/MVP/blob/main/mvp_sprint_ml_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVP | Sprint 1 - Machine Learning & Analytics\n",
        "\n",
        "* Nome: Larissa Silva Cardoso\n",
        "* Matrícula: 4052024000816\n",
        "* Curso: Ciência de Dados e Analytics\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dZjIyiJQYRCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição do Problema\n",
        "\n",
        "O dataset \"load_breast_cancer\" é um conjunto de dados disponível na biblioteca scikit-learn muito utilizado para demonstrar o comportamento de algoritmos de machine learning para problemas de classificação.\n",
        "\n",
        "O objetivo deste código é realizar a classificação de tumores de mama como malignos ou benignos com base em características calculadas a partir de imagens digitalizadas de tecido mamário.\n",
        "\n",
        "Esse código abordará desde a preparação dos dados até a avaliação e comparação dos modelos, proporcionando uma visão geral do processo de classificação.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HD1_ljP3YSa3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparação de Dados\n",
        "\n",
        "1. Configuração para não exibir os avisos.\n",
        "\n",
        "2. Importação das bibliotecas necessárias.\n",
        "\n",
        "3. Importação do conjunto de dados.\n",
        "\n",
        "4. Conversão do conjunto de dados.\n",
        "\n",
        "5. Separação dos atributos e da classe alvo.\n",
        "\n",
        "6. Codificação da classe alvo para converter os rótulos de classe em valores numéricos.\n",
        "\n",
        "7. Divisão da base em conjuntos de treino e teste.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WRqw9W6FYZYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração para não exibir os avisos\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Importação de bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importação do dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Importação dos módulos e algoritmos de classificação do scikit-learn\n",
        "from sklearn.model_selection import train_test_split # particionamento da base em treino e teste (holdout)\n",
        "from sklearn.model_selection import KFold # preparação dos folds da validação cruzada\n",
        "from sklearn.model_selection import cross_val_score # execução da validação cruzada\n",
        "from sklearn.metrics import accuracy_score # exibição da acurácia dos modelos\n",
        "from sklearn.neighbors import KNeighborsClassifier # algoritmo KNN\n",
        "from sklearn.tree import DecisionTreeClassifier # algoritmo Árvore de Classificação\n",
        "from sklearn.naive_bayes import GaussianNB # algoritmo Naive Bayes\n",
        "from sklearn.svm import SVC # algoritmo SVM\n",
        "\n",
        "# Carga do dataset\n",
        "cancer = load_breast_cancer()\n",
        "dataset = pd.DataFrame(cancer.data, columns = cancer.feature_names) # conversão para dataframe\n",
        "dataset[\"target\"] = cancer.target # adição da coluna \"target\"\n",
        "dataset.head() # visualização resumida do dataset (primeiras cinco linhas)"
      ],
      "metadata": {
        "id": "ycwPEsLRY16B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparação dos dados\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Separação em bases de treino e teste (holdout)\n",
        "x = cancer.data # atributos\n",
        "y = cancer.target # classe\n",
        "\n",
        "label_encoder = LabelEncoder() # conversão dos rótulos das classes para valores numéricos\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=7) # divisão das bases"
      ],
      "metadata": {
        "id": "ybG_fAgrY8-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelagem e Treinamento\n",
        "\n",
        "1. Criação dos folds para validação cruzada.\n",
        "2. Definição de seed global para garantir a reprodutibilidade do código com os mesmos resultados.\n",
        "3. Criação de listas para armazenar os modelos, resultados e nomes dos modelos.\n",
        "4. Definição dos modelos de classificação.\n",
        "5. Avaliação dos modelos, treinando cada um deles usando os dados de treinamento e avaliando-os usando validação cruzada.\n",
        "6. Impressão da média e do desvio padrão da acurácia para cada modelo.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rDBdBCV0ZAMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação dos folds para a validação cruzada\n",
        "num_particoes = 10 # número de folds\n",
        "kfold = KFold (n_splits=num_particoes, shuffle=True, random_state=7) # particionamento\n",
        "\n",
        "# Definição de semente glogal\n",
        "np.random.seed(7)\n",
        "\n",
        "# Criação das listas\n",
        "models = []\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Definição dos modelos\n",
        "models.append((\"KNN\", KNeighborsClassifier()))\n",
        "models.append((\"CART\", DecisionTreeClassifier()))\n",
        "models.append((\"NB\", GaussianNB()))\n",
        "models.append((\"SVM\", SVC()))\n",
        "\n",
        "# Avaliação de cada modelo\n",
        "for name, model in models:\n",
        "  cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()) # média e desvio padrão dos 10 resultados da validação cruzada\n",
        "  print (msg)\n"
      ],
      "metadata": {
        "id": "86A6QUKvZFCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação e Resultados\n",
        "\n",
        "1. Visualização dos resultados usando um boxplot para comparar a acurácia e desvio padrão dos diferentes modelos.\n",
        "2. Avaliação de performance dos modelos.\n",
        "3. Criação de modelos com algoritmos que apresentaram melhor resultado.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Sj2GLVG-ZI4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização dos resultados\n",
        "fig = plt.figure()\n",
        "fig.suptitle(\"Comparação da Acurácia dos Modelos\")\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e2o1Kt8rZMKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com base na saída do código e gráfico acima, podemos observar que dois modelos tiveram a média de acurácia superior aos demais. São eles:\n",
        "\n",
        "- KNN (K-nearest neighbours): 0.936232 (0.045443)\n",
        "- NB (Naive Bayes): 0.933720 (0.041136)\n",
        "\n",
        "Os modelos treinados com os algoritmos NKK e NB apresentaram os melhores resultados (93% de acurácia e desvio padrão de 4%).\n",
        "\n",
        "Em relação ao desvio padrão, todos os modelos tiveram um valor relativamente baixo e bem próximos, indicando pouca variabilidade nos resultados.\n",
        "\n",
        "Com isso, abaixo serão criados novos modelos, treinados com toda a base de treino e avaliados utilizando a base de teste.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rCplW_NeZVPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando um modelo com algoritmo KNN com o conjunto de treino\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Fazendo as predições com o conjunto de teste\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Estimando a acurácia no conjunto de teste\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "id": "h59Vrh8QZP2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando um modelo com algoritmo Naive Bayes com o conjunto de treino\n",
        "model = GaussianNB()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Fazendo as predições com o conjunto de teste\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Estimando a acurácia no conjunto de teste\n",
        "print(accuracy_score (y_test, predictions))"
      ],
      "metadata": {
        "id": "t1KMfsetZcr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com as saídas resultantes dos modelos, podemos observar que a acurácia do algoritmo Naive Bayes é maior quando aplicado o conjunto de teste, fazendo com que esse seja o melhor modelo treinado para esse caso.\n",
        "\n",
        "A validação cruzada foi utilizada para reduzir a probabilidade de overfitting dos modelos, o que nesse caso deu certo, dada a pequena diferença de performance do modelo nos dados de treino e teste.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VHX5lCM6Zer_"
      }
    }
  ]
}